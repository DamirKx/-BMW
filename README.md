# –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π BMW

## üìå –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
–ü—Ä–æ–µ–∫—Ç –ø–æ—Å–≤—è—â—ë–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è **–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ä—ã–Ω–æ—á–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π BMW** –ø–æ –∏—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≤ Google Colab –Ω–∞ Python 3.

–ó–∞–¥–∞—á–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–º –∑–∞–¥–∞—á–∞–º –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞:
- –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä–æ–≤, –≤–ª–∏—è—é—â–∏—Ö –Ω–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∞–≤—Ç–æ–º–æ–±–∏–ª—è;
- —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç—Ä—ë—Ö –º–æ–¥–µ–ª–µ–π –ú–õ;
- –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤;
- –≤—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –º–æ–¥–µ–ª–∏.

---

## üìÇ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ
–ò—Å—Ç–æ—á–Ω–∏–∫: –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç **BMW Car Data Analysis** (Kaggle).

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:
| –ü—Ä–∏–∑–Ω–∞–∫ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|----------|
| `model` | –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–æ–±–∏–ª—è |
| `year` | –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞ |
| `price` | –¶–µ–Ω–∞ (—Ç–∞—Ä–≥–µ—Ç) |
| `transmission` | –¢–∏–ø –ö–ü–ü |
| `mileage` | –ü—Ä–æ–±–µ–≥ |
| `fuelType` | –¢–æ–ø–ª–∏–≤–æ |
| `tax` | –ù–∞–ª–æ–≥ |
| `mpg` | –†–∞—Å—Ö–æ–¥ (miles per gallon) |
| `engineSize` | –û–±—ä—ë–º –¥–≤–∏–≥–∞—Ç–µ–ª—è |

---

## üß™ –¶–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
1. –ü—Ä–æ–≤–µ—Å—Ç–∏ —Ä–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (**EDA**).
2. –í—ã–ø–æ–ª–Ω–∏—Ç—å –æ—á–∏—Å—Ç–∫—É, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é, –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ.
3. –û–±—É—á–∏—Ç—å —Ç—Ä–∏ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏:
   - Linear Regression  
   - Random Forest Regressor  
   - XGBoost Regressor  
4. –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º:
   - **MAE**
   - **RMSE**
   - **R¬≤**
5. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–ª–∞–≤–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.
6. –°–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –∏ –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å.

---

## üõ† –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- **Python 3**
- **Google Colab**
- –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏:
  - `pandas`, `numpy`
  - `matplotlib`, `seaborn`
  - `scikit-learn`
  - `xgboost`

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
```

---

## üßπ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
–ù–∞ —ç—Ç–∞–ø–µ Data Cleaning –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:

- —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤;
- –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ —Ü–µ–Ω–µ, –≥–æ–¥—É, –ø—Ä–æ–±–µ–≥—É;
- –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤:
  - —á–∏—Å–ª–æ–≤—ã–µ ‚Üí `median`
  - –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ ‚Üí `most_frequent`
- –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤;
- –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.

```python
# –ö–æ–ª-–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ
print("–ü—Ä–æ–ø—É—Å–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö:")
print(df.isna().sum())

# –£–¥–∞–ª–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫, –µ—Å–ª–∏ –µ—Å—Ç—å
before = df.shape[0]
df = df.drop_duplicates()
after = df.shape[0]
print(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {before - after}")

# –ù–µ–º–Ω–æ–≥–æ –∑–¥—Ä–∞–≤–æ–≥–æ —Å–º—ã—Å–ª–∞ –ø–æ –≤—ã–±—Ä–æ—Å–∞–º (–º–æ–∂–Ω–æ –ø–æ –∂–µ–ª–∞–Ω–∏—é –º–µ–Ω—è—Ç—å / —É–±–∏—Ä–∞—Ç—å):
# –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ü–µ–Ω—ã, –ø—Ä–æ–±–µ–≥–∞ –∏ –≥–æ–¥–∞
df = df[(df['price'] > 500) & (df['price'] < 100000)]
df = df[(df['mileage'] >= 0) & (df['mileage'] < 300000)]
df = df[(df['year'] >= 1990)]  # —Å—Ç–∞—Ä—ã–µ –º–∞—à–∏–Ω—ã –æ—Ç—Å–µ—á—ë–º

print("–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤—ã–±—Ä–æ—Å–æ–≤:", df.shape)
```

```python
# –ù–∞—à —Ç–∞—Ä–≥–µ—Ç ‚Äì price
target_col = 'price'

# –°–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
numeric_features = ['year', 'mileage', 'tax', 'mpg', 'engineSize']
categorical_features = ['model', 'transmission', 'fuelType']

print("–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:", numeric_features)
print("–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:", categorical_features)
```

---

## üìä EDA –∏ –∞–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π

–û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è:
- **corr(year, price) > 0**  
  –ù–æ–≤—ã–µ –º–∞—à–∏–Ω—ã —Å—Ç–æ—è—Ç –¥–æ—Ä–æ–∂–µ ‚Äî –ª–æ–≥–∏—á–Ω–∞—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å.
- **corr(mileage, price) < 0**  
  –ß–µ–º –±–æ–ª—å—à–µ –ø—Ä–æ–±–µ–≥, —Ç–µ–º –Ω–∏–∂–µ —Å—Ç–æ–∏–º–æ—Å—Ç—å.
- –ú–æ–¥–µ–ª–∏ **X**, **M**, **Series 6‚Äì7** —Å—Ç–æ—è—Ç –¥–æ—Ä–æ–∂–µ.
- –¢–∏–ø —Ç–æ–ø–ª–∏–≤–∞ –∏ –∫–æ—Ä–æ–±–∫–∞ –ø–µ—Ä–µ–¥–∞—á —Ç–∞–∫–∂–µ –≤–ª–∏—è—é—Ç –Ω–∞ —Ü–µ–Ω—É.

–ü–æ—Å—Ç—Ä–æ–µ–Ω—ã –≥—Ä–∞—Ñ–∏–∫–∏:
- —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–Ω—ã, –ø—Ä–æ–±–µ–≥–∞, –≥–æ–¥–∞;
- –º–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π;
- scatter-–≥—Ä–∞—Ñ–∏–∫–∏ —Ü–µ–Ω–∞‚Äì–≥–æ–¥ –∏ —Ü–µ–Ω–∞‚Äì–ø—Ä–æ–±–µ–≥.

```python
corr_matrix = df[numeric_features + [target_col]].corr()

print("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞:")
print(corr_matrix)

# –ù–∞–π–¥—ë–º –ø–∞—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π > 0.8
upper = corr_matrix.abs().where(
    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
)

high_corr_pairs = []
for i in upper.index:
    for j in upper.columns:
        if (upper.loc[i, j] > 0.8) and not np.isnan(upper.loc[i, j]):
            high_corr_pairs.append((i, j, upper.loc[i, j]))

print("\n–ü–∞—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π (> 0.8):")
for pair in high_corr_pairs:
    print(pair)
```
---

## üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–µ–π

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–æ–Ω–≤–µ–π–µ—Ä (**Pipeline**) —Å:

- –º–∞—Å—à—Ç. —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí `StandardScaler`
- one-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí `OneHotEncoder`
- –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ `ColumnTransformer`

–≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
- –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤;
- –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —É—Ç–µ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö;
- —É–¥–æ–±—Å—Ç–≤–æ –ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–µ–π.

```python
X = df.drop(columns=[target_col])
y = df[target_col]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("–†–∞–∑–º–µ—Ä X_train:", X_train.shape)
print("–†–∞–∑–º–µ—Ä X_test:", X_test.shape)
```

```python
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),      # –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –º–µ–¥–∏–∞–Ω–æ–π
    ('scaler', StandardScaler())                        # –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –º–æ–¥–æ–π
    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # one-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)
```

---

## ü§ñ –û–±—É—á–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### **1) –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è**
–ü—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–∞—è –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.

### **2) Random Forest Regressor**
–ê–Ω—Å–∞–º–±–ª—å –¥–µ—Ä–µ–≤—å–µ–≤ ‚Üí —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—è–º–∏.

### **3) XGBoost Regressor**
–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ ‚Üí –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å.

```python
models = {
    "LinearRegression": LinearRegression(),
    "RandomForest": RandomForestRegressor(
        n_estimators=200,
        max_depth=None,
        random_state=42,
        n_jobs=-1
    ),
    "XGBoost": XGBRegressor(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=4,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42
    )
}
```

---

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π

–í –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã:

### **MAE ‚Äî —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞**
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞ —Å–∫–æ–ª—å–∫–æ –¥–æ–ª–ª–∞—Ä–æ–≤ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è –≤ —Å—Ä–µ–¥–Ω–µ–º.

### **RMSE ‚Äî –∫–æ—Ä–µ–Ω—å –∏–∑ –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –æ—à–∏–±–∫–∏**
–®—Ç—Ä–∞—Ñ—É–µ—Ç –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏, —Å—Ç—Ä–æ–≥–∞—è –º–µ—Ç—Ä–∏–∫–∞.

### **R¬≤ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏**
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫—É—é –¥–æ–ª—é –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ–±—ä—è—Å–Ω—è–µ—Ç –º–æ–¥–µ–ª—å.

```python
# 9. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ MAE, RMSE, R^2
results = []

for name, model in models.items():
    clf = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    
    clf.fit(X_train, y_train)
    
    y_pred = clf.predict(X_test)

    # –ú–µ—Ç—Ä–∏–∫–∏
    mae = mean_absolute_error(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred) ** 0.5   # –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ!
    r2 = r2_score(y_test, y_pred)

    results.append({
        "model": name,
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2
    })

results_df = pd.DataFrame(results)
display(results_df.sort_values(by="RMSE"))
```

---

## üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (–ø—Ä–∏–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã)

| –ú–æ–¥–µ–ª—å | MAE | RMSE | R¬≤ |
|--------|------|---------|------|
| Linear Regression | 2810.169759 | 4041.810257 | 0.875150 |
| Random Forest | 1551.333646 | 2363.928326 | 0.957292 |
| XGBoost | 1680.563721 | 2417.115740 | 0.955349 |

‚ö° –û–∂–∏–¥–∞–µ–º–æ –ª—É—á—à–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±–ª–∞–¥–∞–µ—Ç **XGBoost** –∏–ª–∏ **Random Forest**, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

---

## üìâ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
–ü–æ—Å—Ç—Ä–æ–µ–Ω—ã –≥—Ä–∞—Ñ–∏–∫–∏:

- –¶–µ–Ω–∞ vs –ü—Ä–æ–±–µ–≥  
- –¶–µ–Ω–∞ vs –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞  
- –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (feature importance)

–û–Ω–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å:
- –∫–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ –≤–ª–∏—è—é—Ç –Ω–∞ —Ü–µ–Ω—É;
- –∫–∞–∫ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è —Å—Ç–æ–∏–º–æ—Å—Ç—å BMW –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–±–µ–≥–∞ –∏ –≤–æ–∑—Ä–∞—Å—Ç–∞.

```python
plt.figure(figsize=(7, 5))
plt.scatter(df['mileage'], df['price'], alpha=0.4)
plt.xlabel("–ü—Ä–æ–±–µ–≥ (mileage)")
plt.ylabel("–¶–µ–Ω–∞ (price)")
plt.title("–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –ø—Ä–æ–±–µ–≥–∞")
plt.grid(True)
plt.show()

plt.figure(figsize=(7, 5))
plt.scatter(df['year'], df['price'], alpha=0.4)
plt.xlabel("–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞ (year)")
plt.ylabel("–¶–µ–Ω–∞ (price)")
plt.title("–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –≥–æ–¥–∞ –≤—ã–ø—É—Å–∫–∞")
plt.grid(True)
plt.show()
```
<img width="830" height="585" alt="image" src="https://github.com/user-attachments/assets/f187c2bf-f628-43ca-a871-fa40c15d266b" />

<img width="832" height="589" alt="image" src="https://github.com/user-attachments/assets/7c5e0051-2f70-436e-9251-1426161c637e" />



---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

